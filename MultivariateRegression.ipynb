{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a small little data set of Blue Book car values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('http://cdn.sundog-soft.com/Udemy/DataScience/cars.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>Type</th>\n",
       "      <th>Cylinder</th>\n",
       "      <th>Liter</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Sound</th>\n",
       "      <th>Leather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17314.103129</td>\n",
       "      <td>8221</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17542.036083</td>\n",
       "      <td>9135</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16218.847862</td>\n",
       "      <td>13196</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16336.913140</td>\n",
       "      <td>16342</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16339.170324</td>\n",
       "      <td>19832</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15709.052821</td>\n",
       "      <td>22236</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15230.003390</td>\n",
       "      <td>22576</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15048.042184</td>\n",
       "      <td>22964</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14862.093870</td>\n",
       "      <td>24021</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15295.018267</td>\n",
       "      <td>27325</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21335.852485</td>\n",
       "      <td>10237</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20538.087510</td>\n",
       "      <td>15066</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20512.094091</td>\n",
       "      <td>16633</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19924.159052</td>\n",
       "      <td>19800</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19774.249066</td>\n",
       "      <td>23359</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19344.165537</td>\n",
       "      <td>23765</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19105.130124</td>\n",
       "      <td>24008</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18543.427045</td>\n",
       "      <td>26034</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17808.198996</td>\n",
       "      <td>32896</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17968.838278</td>\n",
       "      <td>34665</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Lacrosse</td>\n",
       "      <td>CX Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Price  Mileage   Make     Model         Trim   Type  Cylinder  \\\n",
       "0   17314.103129     8221  Buick   Century     Sedan 4D  Sedan         6   \n",
       "1   17542.036083     9135  Buick   Century     Sedan 4D  Sedan         6   \n",
       "2   16218.847862    13196  Buick   Century     Sedan 4D  Sedan         6   \n",
       "3   16336.913140    16342  Buick   Century     Sedan 4D  Sedan         6   \n",
       "4   16339.170324    19832  Buick   Century     Sedan 4D  Sedan         6   \n",
       "5   15709.052821    22236  Buick   Century     Sedan 4D  Sedan         6   \n",
       "6   15230.003390    22576  Buick   Century     Sedan 4D  Sedan         6   \n",
       "7   15048.042184    22964  Buick   Century     Sedan 4D  Sedan         6   \n",
       "8   14862.093870    24021  Buick   Century     Sedan 4D  Sedan         6   \n",
       "9   15295.018267    27325  Buick   Century     Sedan 4D  Sedan         6   \n",
       "10  21335.852485    10237  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "11  20538.087510    15066  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "12  20512.094091    16633  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "13  19924.159052    19800  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "14  19774.249066    23359  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "15  19344.165537    23765  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "16  19105.130124    24008  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "17  18543.427045    26034  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "18  17808.198996    32896  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "19  17968.838278    34665  Buick  Lacrosse  CX Sedan 4D  Sedan         6   \n",
       "\n",
       "    Liter  Doors  Cruise  Sound  Leather  \n",
       "0     3.1      4       1      1        1  \n",
       "1     3.1      4       1      1        0  \n",
       "2     3.1      4       1      1        0  \n",
       "3     3.1      4       1      0        0  \n",
       "4     3.1      4       1      0        1  \n",
       "5     3.1      4       1      1        0  \n",
       "6     3.1      4       1      1        0  \n",
       "7     3.1      4       1      1        0  \n",
       "8     3.1      4       1      0        1  \n",
       "9     3.1      4       1      1        1  \n",
       "10    3.6      4       1      0        0  \n",
       "11    3.6      4       1      1        0  \n",
       "12    3.6      4       1      1        0  \n",
       "13    3.6      4       1      1        1  \n",
       "14    3.6      4       1      1        1  \n",
       "15    3.6      4       1      1        0  \n",
       "16    3.6      4       1      0        0  \n",
       "17    3.6      4       1      1        1  \n",
       "18    3.6      4       1      1        0  \n",
       "19    3.6      4       1      1        1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pandas to split up this matrix into the feature vectors we're interested in, and the value we're trying to predict.\n",
    "\n",
    "Note how we are avoiding the make and model; regressions don't work well with ordinal values, unless you can convert them into some numerical order that makes sense somehow.\n",
    "\n",
    "Let's scale our feature data into the same range so we can easily compare the coefficients we end up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.41748516,  0.52741047,  0.55627894],\n",
       "       [-1.30590228,  0.52741047,  0.55627894],\n",
       "       [-0.81012759,  0.52741047,  0.55627894],\n",
       "       ...,\n",
       "       [ 0.07960546,  0.52741047,  0.55627894],\n",
       "       [ 0.75044563,  0.52741047,  0.55627894],\n",
       "       [ 1.93256489,  0.52741047,  0.55627894]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Mileage', 'Cylinder', 'Doors']]\n",
    "X_scaled = scale.fit_transform(X.values)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OLS in module statsmodels.regression.linear_model:\n",
      "\n",
      "class OLS(WLS)\n",
      " |  OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |  \n",
      " |  A simple ordinary least squares model.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array-like\n",
      " |      1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array-like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none.'\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights : scalar\n",
      " |      Has an attribute weights = array(1.0) due to inheritance from WLS.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  GLS\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>>\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>>\n",
      " |  >>> Y = [1,3,4,5,2,3,4]\n",
      " |  >>> X = range(1,8)\n",
      " |  >>> X = sm.add_constant(X)\n",
      " |  >>>\n",
      " |  >>> model = sm.OLS(Y,X)\n",
      " |  >>> results = model.fit()\n",
      " |  >>> results.params\n",
      " |  array([ 2.14285714,  0.25      ])\n",
      " |  >>> results.tvalues\n",
      " |  array([ 1.87867287,  0.98019606])\n",
      " |  >>> print(results.t_test([1, 0]))\n",
      " |  <T test: effect=array([ 2.14285714]), sd=array([[ 1.14062282]]), t=array([[ 1.87867287]]), p=array([[ 0.05953974]]), df_denom=5>\n",
      " |  >>> print(results.f_test(np.identity(2)))\n",
      " |  <F test: F=array([[ 19.46078431]]), p=[[ 0.00437251]], df_denom=5, df_num=2>\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  No constant is added by the model unless you are using formulas.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OLS\n",
      " |      WLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : string\n",
      " |          Only the 'elastic_net' approach is currently implemented.\n",
      " |      alpha : scalar or array-like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt: scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array-like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      distributed : bool\n",
      " |          If True, the model uses distributed methods for fitting,\n",
      " |          will raise an error if True and partitions is None.\n",
      " |      generator : function\n",
      " |          generator used to partition the model, allows for handling\n",
      " |          of out of memory/parallel computing.\n",
      " |      partitions : scalar\n",
      " |          The number of partitions desired for the distributed\n",
      " |          estimation.\n",
      " |      threshold : scalar or array-like\n",
      " |          The threshold below which coefficients are zeroed out,\n",
      " |          only used for distributed estimation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A RegularizedResults instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      The elastic net approach closely follows that implemented in\n",
      " |      the glmnet package in R.  The penalty is a combination of L1\n",
      " |      and L2 penalties.\n",
      " |      \n",
      " |      The function that is minimized is:\n",
      " |      \n",
      " |      .. math::\n",
      " |      \n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |      \n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |      \n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |      \n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |      \n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |      \n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |      generalized linear models via coordinate descent.  Journal of\n",
      " |      Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |  \n",
      " |  hessian(self, params, scale=None)\n",
      " |      Evaluate the Hessian function at a given point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The parameter vector at which the Hessian is computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The Hessian matrix.\n",
      " |  \n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Weights for calculating Hessian\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          parameter at which Hessian is evaluated\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      hessian_factor : ndarray, 1d\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      " |  \n",
      " |  loglike(self, params, scale=None)\n",
      " |      The likelihood function for the OLS model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The coefficients with which to estimate the log-likelihood.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The likelihood function evaluated at params.\n",
      " |  \n",
      " |  score(self, params, scale=None)\n",
      " |      Evaluate the score function at a given point.\n",
      " |      \n",
      " |      The score corresponds to the profile (concentrated)\n",
      " |      log-likelihood in which the scale parameter has been profiled\n",
      " |      out.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The parameter vector at which the score function is\n",
      " |          computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The score vector.\n",
      " |  \n",
      " |  whiten(self, Y)\n",
      " |      OLS model whitener does nothing: returns Y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |  \n",
      " |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |      Full fit of the model.\n",
      " |      \n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance estimators\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A RegressionResults class instance.\n",
      " |      \n",
      " |      See Also\n",
      " |      ---------\n",
      " |      regression.linear_model.RegressionResults\n",
      " |      regression.linear_model.RegressionResults.get_robustcov_results\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |  \n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Returns a random number generator for the predictive distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array-like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to Gaussian.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize (possibly re-initialize) a Model instance. For\n",
      " |      instance, the design matrix of a linear model may change\n",
      " |      and some things must be recomputed.\n",
      " |  \n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          Parameters of a linear model\n",
      " |      exog : array-like, optional.\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      An array of fitted values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |  \n",
      " |  df_model\n",
      " |      The model degree of freedom, defined as the rank of the regressor\n",
      " |      matrix minus 1 if a constant is included.\n",
      " |  \n",
      " |  df_resid\n",
      " |      The residual degree of freedom, defined as the number of observations\n",
      " |      minus the rank of the regressor matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model\n",
      " |      \n",
      " |      Returns -Hessian of loglike evaluated at params.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model\n",
      " |      data : array-like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array-like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`\n",
      " |      drop_cols : array-like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      args : extra arguments\n",
      " |          These are passed to the model\n",
      " |      kwargs : extra keyword arguments\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : Model instance\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "help(statsmodels.api.OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/gurupratap/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Mileage  Cylinder     Doors\n",
      "0   -1.417485  0.527410  0.556279\n",
      "1   -1.305902  0.527410  0.556279\n",
      "2   -0.810128  0.527410  0.556279\n",
      "3   -0.426058  0.527410  0.556279\n",
      "4    0.000008  0.527410  0.556279\n",
      "5    0.293493  0.527410  0.556279\n",
      "6    0.335001  0.527410  0.556279\n",
      "7    0.382369  0.527410  0.556279\n",
      "8    0.511409  0.527410  0.556279\n",
      "9    0.914768  0.527410  0.556279\n",
      "10  -1.171368  0.527410  0.556279\n",
      "11  -0.581834  0.527410  0.556279\n",
      "12  -0.390532  0.527410  0.556279\n",
      "13  -0.003899  0.527410  0.556279\n",
      "14   0.430591  0.527410  0.556279\n",
      "15   0.480156  0.527410  0.556279\n",
      "16   0.509822  0.527410  0.556279\n",
      "17   0.757160  0.527410  0.556279\n",
      "18   1.594886  0.527410  0.556279\n",
      "19   1.810849  0.527410  0.556279\n",
      "20  -1.326046  0.527410  0.556279\n",
      "21  -1.129860  0.527410  0.556279\n",
      "22  -0.667658  0.527410  0.556279\n",
      "23  -0.405792  0.527410  0.556279\n",
      "24  -0.112796  0.527410  0.556279\n",
      "25  -0.044552  0.527410  0.556279\n",
      "26   0.190700  0.527410  0.556279\n",
      "27   0.337442  0.527410  0.556279\n",
      "28   0.566102  0.527410  0.556279\n",
      "29   0.660837  0.527410  0.556279\n",
      "..        ...       ...       ...\n",
      "774 -0.161262 -0.914896  0.556279\n",
      "775 -0.089234 -0.914896  0.556279\n",
      "776 -0.040523 -0.914896  0.556279\n",
      "777  0.002572 -0.914896  0.556279\n",
      "778  0.236603 -0.914896  0.556279\n",
      "779  0.249666 -0.914896  0.556279\n",
      "780  0.357220 -0.914896  0.556279\n",
      "781  0.365521 -0.914896  0.556279\n",
      "782  0.434131 -0.914896  0.556279\n",
      "783  0.517269 -0.914896  0.556279\n",
      "784  0.589908 -0.914896  0.556279\n",
      "785  0.599186 -0.914896  0.556279\n",
      "786  0.793052 -0.914896  0.556279\n",
      "787  1.033554 -0.914896  0.556279\n",
      "788  1.045762 -0.914896  0.556279\n",
      "789  1.205567 -0.914896  0.556279\n",
      "790  1.541414 -0.914896  0.556279\n",
      "791  1.561070 -0.914896  0.556279\n",
      "792  1.725026 -0.914896  0.556279\n",
      "793  1.851502 -0.914896  0.556279\n",
      "794 -1.709871  0.527410  0.556279\n",
      "795 -1.474375  0.527410  0.556279\n",
      "796 -1.187849  0.527410  0.556279\n",
      "797 -1.079929  0.527410  0.556279\n",
      "798 -0.682430  0.527410  0.556279\n",
      "799 -0.439853  0.527410  0.556279\n",
      "800 -0.089966  0.527410  0.556279\n",
      "801  0.079605  0.527410  0.556279\n",
      "802  0.750446  0.527410  0.556279\n",
      "803  1.932565  0.527410  0.556279\n",
      "\n",
      "[804 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.064</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   18.11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 16 May 2019</td> <th>  Prob (F-statistic):</th> <td>2.23e-11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:49</td>     <th>  Log-Likelihood:    </th> <td> -9207.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   804</td>      <th>  AIC:               </th> <td>1.842e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   801</td>      <th>  BIC:               </th> <td>1.843e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mileage</th>  <td>-1272.3412</td> <td>  804.623</td> <td>   -1.581</td> <td> 0.114</td> <td>-2851.759</td> <td>  307.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cylinder</th> <td> 5587.4472</td> <td>  804.509</td> <td>    6.945</td> <td> 0.000</td> <td> 4008.252</td> <td> 7166.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Doors</th>    <td>-1404.5513</td> <td>  804.275</td> <td>   -1.746</td> <td> 0.081</td> <td>-2983.288</td> <td>  174.185</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>157.913</td> <th>  Durbin-Watson:     </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 257.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.278</td>  <th>  Prob(JB):          </th> <td>1.20e-56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.074</td>  <th>  Cond. No.          </th> <td>    1.03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.064\n",
       "Model:                            OLS   Adj. R-squared:                  0.060\n",
       "Method:                 Least Squares   F-statistic:                     18.11\n",
       "Date:                Thu, 16 May 2019   Prob (F-statistic):           2.23e-11\n",
       "Time:                        20:15:49   Log-Likelihood:                -9207.1\n",
       "No. Observations:                 804   AIC:                         1.842e+04\n",
       "Df Residuals:                     801   BIC:                         1.843e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Mileage    -1272.3412    804.623     -1.581      0.114   -2851.759     307.077\n",
       "Cylinder    5587.4472    804.509      6.945      0.000    4008.252    7166.642\n",
       "Doors      -1404.5513    804.275     -1.746      0.081   -2983.288     174.185\n",
       "==============================================================================\n",
       "Omnibus:                      157.913   Durbin-Watson:                   0.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              257.529\n",
       "Skew:                           1.278   Prob(JB):                     1.20e-56\n",
       "Kurtosis:                       4.074   Cond. No.                         1.03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "X = df[['Mileage', 'Cylinder', 'Doors']]\n",
    "y = df['Price']\n",
    "\n",
    "X[['Mileage', 'Cylinder', 'Doors']] = scale.fit_transform(X[['Mileage', 'Cylinder', 'Doors']].as_matrix())\n",
    "\n",
    "print (X)\n",
    "\n",
    "est = sm.OLS(y, X).fit()\n",
    "\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Cylinder</th>\n",
       "      <th>Liter</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Sound</th>\n",
       "      <th>Leather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143051</td>\n",
       "      <td>0.569086</td>\n",
       "      <td>0.558146</td>\n",
       "      <td>-0.138750</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>-0.124348</td>\n",
       "      <td>0.157197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mileage</th>\n",
       "      <td>-0.143051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029461</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>-0.016944</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>-0.026146</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cylinder</th>\n",
       "      <td>0.569086</td>\n",
       "      <td>-0.029461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957897</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.354285</td>\n",
       "      <td>-0.089704</td>\n",
       "      <td>0.075520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liter</th>\n",
       "      <td>0.558146</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>0.957897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079259</td>\n",
       "      <td>0.377509</td>\n",
       "      <td>-0.065527</td>\n",
       "      <td>0.087332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doors</th>\n",
       "      <td>-0.138750</td>\n",
       "      <td>-0.016944</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>-0.079259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047674</td>\n",
       "      <td>-0.062530</td>\n",
       "      <td>-0.061969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cruise</th>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.354285</td>\n",
       "      <td>0.377509</td>\n",
       "      <td>-0.047674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091730</td>\n",
       "      <td>-0.070573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sound</th>\n",
       "      <td>-0.124348</td>\n",
       "      <td>-0.026146</td>\n",
       "      <td>-0.089704</td>\n",
       "      <td>-0.065527</td>\n",
       "      <td>-0.062530</td>\n",
       "      <td>-0.091730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leather</th>\n",
       "      <td>0.157197</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.075520</td>\n",
       "      <td>0.087332</td>\n",
       "      <td>-0.061969</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>0.165444</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price   Mileage  Cylinder     Liter     Doors    Cruise  \\\n",
       "Price     1.000000 -0.143051  0.569086  0.558146 -0.138750  0.430851   \n",
       "Mileage  -0.143051  1.000000 -0.029461 -0.018641 -0.016944  0.025037   \n",
       "Cylinder  0.569086 -0.029461  1.000000  0.957897  0.002206  0.354285   \n",
       "Liter     0.558146 -0.018641  0.957897  1.000000 -0.079259  0.377509   \n",
       "Doors    -0.138750 -0.016944  0.002206 -0.079259  1.000000 -0.047674   \n",
       "Cruise    0.430851  0.025037  0.354285  0.377509 -0.047674  1.000000   \n",
       "Sound    -0.124348 -0.026146 -0.089704 -0.065527 -0.062530 -0.091730   \n",
       "Leather   0.157197  0.001005  0.075520  0.087332 -0.061969 -0.070573   \n",
       "\n",
       "             Sound   Leather  \n",
       "Price    -0.124348  0.157197  \n",
       "Mileage  -0.026146  0.001005  \n",
       "Cylinder -0.089704  0.075520  \n",
       "Liter    -0.065527  0.087332  \n",
       "Doors    -0.062530 -0.061969  \n",
       "Cruise   -0.091730 -0.070573  \n",
       "Sound     1.000000  0.165444  \n",
       "Leather   0.165444  1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The table of coefficients above gives us the values to plug into an equation of form:\n",
    "    B0 + B1 * Mileage + B2 * model_ord + B3 * doors\n",
    "    \n",
    "In this example, it's pretty clear that the number of cylinders is more important than anything based on the coefficients.\n",
    "\n",
    "Could we have figured that out earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doors\n",
       "2    23807.135520\n",
       "4    20580.670749\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.groupby(df.Doors).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, more doors does not mean a higher price! (Maybe it implies a sport car in some cases?) So it's not surprising that it's pretty useless as a predictor here. This is a very small data set however, so we can't really read much meaning into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mess around with the fake input data, and see if you can create a measurable influence of number of doors on price. Have some fun with it - why stop at 4 doors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
